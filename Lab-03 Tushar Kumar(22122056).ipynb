{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0b479c",
   "metadata": {},
   "source": [
    "# Lab-03\n",
    "## Tushar Kumar\n",
    "### 3MSCDSA\n",
    "### 22122056\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be981a6",
   "metadata": {},
   "source": [
    "### 1. To tokenize the document (article, news, story, assay) of Indian Language and find the frequency count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5eb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the neccessary library- \n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51fec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the PDF file\n",
    "pdf_file = open(\"hinditext.pdf\", \"rb\")\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdab28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from each page\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e3740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the PDF file\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0161756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: indic-nlp-library in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (0.92)\n",
      "Requirement already satisfied: numpy in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.22.4)\n",
      "Requirement already satisfied: morfessor in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from indic-nlp-library) (2.0.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.4.2)\n",
      "Requirement already satisfied: sphinx-argparse in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from indic-nlp-library) (0.4.0)\n",
      "Requirement already satisfied: sphinx-rtd-theme in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from indic-nlp-library) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from pandas->indic-nlp-library) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->indic-nlp-library) (1.16.0)\n",
      "Requirement already satisfied: sphinx>=1.2.0 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx-argparse->indic-nlp-library) (4.4.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: babel>=1.3 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.9.1)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.7.12)\n",
      "Requirement already satisfied: requests>=2.5.0 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.27.1)\n",
      "Requirement already satisfied: imagesize in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.3.0)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.4.6)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.1.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (21.3)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (4.11.3)\n",
      "Requirement already satisfied: docutils<0.18,>=0.14 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (0.17.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.0.2)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.3)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.11.2)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from Jinja2>=2.3->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from requests>=2.5.0->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (1.26.9)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library) (3.0.4)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in c:\\users\\tkuma\\anaconda3\\lib\\site-packages (from sphinx-rtd-theme->indic-nlp-library) (4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install indic-nlp-library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad73c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['सभी']\n",
      "['को']\n",
      "['नमस्ते']\n",
      "['!']\n",
      "['आज']\n",
      "['हम']\n",
      "['सभी']\n",
      "['एक']\n",
      "['साथ']\n",
      "['एक']\n",
      "['अच्छा']\n",
      "['समय']\n",
      "['बिता']\n",
      "['रहे']\n",
      "['हैं']\n",
      "['।']\n",
      "['यहााँ']\n",
      "['पर']\n",
      "['सभी']\n",
      "['बमलकर']\n",
      "['बमलने']\n",
      "['के']\n",
      "['बलए']\n",
      "['एक']\n",
      "['\\nअवसर']\n",
      "['है']\n",
      "['।']\n",
      "['हम']\n",
      "['एक']\n",
      "['दूसरे']\n",
      "['के']\n",
      "['साथ']\n",
      "['बमलकर']\n",
      "['खुबियोों']\n",
      "['और']\n",
      "['समृद्धि']\n",
      "['की']\n",
      "['िातें']\n",
      "['कर']\n",
      "['रहे']\n",
      "['हैं']\n",
      "['।']\n",
      "['आपका']\n",
      "['स्वागत']\n",
      "['है']\n",
      "['हमारी']\n",
      "['\\nसमृद्धि']\n",
      "['और']\n",
      "['सोंिोंधोों']\n",
      "['की']\n",
      "['ऊ']\n",
      "['ाँ']\n",
      "['चाईयोों']\n",
      "['में']\n",
      "['।']\n",
      "['हम']\n",
      "['सभी']\n",
      "['बमलकर']\n",
      "['एक']\n",
      "['सजीव']\n",
      "[',']\n",
      "['सफल']\n",
      "['और']\n",
      "['प्यार']\n",
      "['भरी']\n",
      "['बजन्दगी']\n",
      "['जीने']\n",
      "['के']\n",
      "['बलए']\n",
      "['\\nप्रेररत']\n",
      "['होते']\n",
      "['हैं']\n",
      "['।']\n",
      "['आओ']\n",
      "[',']\n",
      "['इस']\n",
      "['सोंगठन']\n",
      "['के']\n",
      "['उद्देश्य']\n",
      "['की']\n",
      "['प्राद्धि']\n",
      "['के']\n",
      "['बलए']\n",
      "['समथथन']\n",
      "['करें']\n",
      "['और']\n",
      "['एक']\n",
      "['सिक्त']\n",
      "['योगदान']\n",
      "['दें']\n",
      "['।']\n",
      "['धन्यवाद']\n",
      "['!']\n",
      "<FreqDist with 58 samples and 93 outcomes>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "#Tokenize sentences\n",
    "sentences = sentence_tokenize.sentence_split(text, lang='hi')\n",
    "\n",
    "# Tokenize words within each sentence\n",
    "tokenized_sentences = [word for sentence in sentences for word in indic_tokenize.trivial_tokenize(sentence)]\n",
    "\n",
    "# Creating a frequency distribution of tokens:\n",
    "frequency_dist = FreqDist(tokenized_sentences)\n",
    "\n",
    "#Print tokenized sentences\n",
    "for hindi_tokens in tokenized_sentences:\n",
    "    print(indic_tokenize.trivial_tokenize(hindi_tokens))\n",
    "\n",
    "# Print the frequency distribution\n",
    "print(frequency_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb87298e",
   "metadata": {},
   "source": [
    "__Creating a dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8263a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9f4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the frequency distribution to a dictionary\n",
    "frequency_dict = dict(frequency_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca2d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "df_indian = pd.DataFrame(list(frequency_dist.items()),columns=[\"Token\",\"Frequency_Indian\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d521bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency_Indian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>सभी</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>को</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>नमस्ते</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>आज</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>हम</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>एक</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>साथ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>अच्छा</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>समय</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>बिता</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>रहे</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>हैं</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>।</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>यहााँ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>पर</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>बमलकर</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>बमलने</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>के</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>बलए</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>\\nअवसर</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>है</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>दूसरे</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>खुबियोों</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>और</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>समृद्धि</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>की</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>िातें</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>कर</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>आपका</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>स्वागत</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>हमारी</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\\nसमृद्धि</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>सोंिोंधोों</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ऊ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ाँ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>चाईयोों</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>में</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>सजीव</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>सफल</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>प्यार</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>भरी</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>बजन्दगी</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>जीने</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\\nप्रेररत</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>होते</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>आओ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>इस</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>सोंगठन</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>उद्देश्य</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>प्राद्धि</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>समथथन</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>करें</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>सिक्त</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>योगदान</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>दें</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>धन्यवाद</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Token  Frequency_Indian\n",
       "0          सभी                 4\n",
       "1           को                 1\n",
       "2       नमस्ते                 1\n",
       "3            !                 2\n",
       "4           आज                 1\n",
       "5           हम                 3\n",
       "6           एक                 6\n",
       "7          साथ                 2\n",
       "8        अच्छा                 1\n",
       "9          समय                 1\n",
       "10        बिता                 1\n",
       "11         रहे                 2\n",
       "12         हैं                 3\n",
       "13           ।                 6\n",
       "14       यहााँ                 1\n",
       "15          पर                 1\n",
       "16       बमलकर                 3\n",
       "17       बमलने                 1\n",
       "18          के                 5\n",
       "19         बलए                 3\n",
       "20      \\nअवसर                 1\n",
       "21          है                 2\n",
       "22       दूसरे                 1\n",
       "23    खुबियोों                 1\n",
       "24          और                 4\n",
       "25     समृद्धि                 1\n",
       "26          की                 3\n",
       "27       िातें                 1\n",
       "28          कर                 1\n",
       "29        आपका                 1\n",
       "30      स्वागत                 1\n",
       "31       हमारी                 1\n",
       "32   \\nसमृद्धि                 1\n",
       "33  सोंिोंधोों                 1\n",
       "34           ऊ                 1\n",
       "35          ाँ                 1\n",
       "36     चाईयोों                 1\n",
       "37         में                 1\n",
       "38        सजीव                 1\n",
       "39           ,                 2\n",
       "40         सफल                 1\n",
       "41       प्यार                 1\n",
       "42         भरी                 1\n",
       "43     बजन्दगी                 1\n",
       "44        जीने                 1\n",
       "45   \\nप्रेररत                 1\n",
       "46        होते                 1\n",
       "47          आओ                 1\n",
       "48          इस                 1\n",
       "49      सोंगठन                 1\n",
       "50    उद्देश्य                 1\n",
       "51    प्राद्धि                 1\n",
       "52       समथथन                 1\n",
       "53        करें                 1\n",
       "54       सिक्त                 1\n",
       "55      योगदान                 1\n",
       "56         दें                 1\n",
       "57     धन्यवाद                 1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_indian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d9cea",
   "metadata": {},
   "source": [
    "__FINDING STEMS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc7c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import ISRIStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f6469c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Hindi Stemming\n",
    "\n",
    "def stem_hindi(word):\n",
    "    hindi_stemmer = ISRIStemmer()\n",
    "    word = hindi_stemmer.stem(word)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1152d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply stemming for Hindi:\n",
    "df_indian['Stem_hindi']=df_indian[\"Token\"].apply(stem_hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "425812f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Token  Frequency_Indian  Stem_hindi\n",
      "0          सभी                 4         सभी\n",
      "1           को                 1          को\n",
      "2       नमस्ते                 1      नमस्ते\n",
      "3            !                 2           !\n",
      "4           आज                 1          आज\n",
      "5           हम                 3          हम\n",
      "6           एक                 6          एक\n",
      "7          साथ                 2         साथ\n",
      "8        अच्छा                 1       अच्छा\n",
      "9          समय                 1         समय\n",
      "10        बिता                 1        बिता\n",
      "11         रहे                 2         रहे\n",
      "12         हैं                 3         हैं\n",
      "13           ।                 6           ।\n",
      "14       यहााँ                 1       यहााँ\n",
      "15          पर                 1          पर\n",
      "16       बमलकर                 3       बमलकर\n",
      "17       बमलने                 1       बमलने\n",
      "18          के                 5          के\n",
      "19         बलए                 3         बलए\n",
      "20      \\nअवसर                 1      \\nअवसर\n",
      "21          है                 2          है\n",
      "22       दूसरे                 1       दूसरे\n",
      "23    खुबियोों                 1    खुबियोों\n",
      "24          और                 4          और\n",
      "25     समृद्धि                 1     समृद्धि\n",
      "26          की                 3          की\n",
      "27       िातें                 1       िातें\n",
      "28          कर                 1          कर\n",
      "29        आपका                 1        आपका\n",
      "30      स्वागत                 1      स्वागत\n",
      "31       हमारी                 1       हमारी\n",
      "32   \\nसमृद्धि                 1   \\nसमृद्धि\n",
      "33  सोंिोंधोों                 1  सोंिोंधोों\n",
      "34           ऊ                 1           ऊ\n",
      "35          ाँ                 1          ाँ\n",
      "36     चाईयोों                 1     चाईयोों\n",
      "37         में                 1         में\n",
      "38        सजीव                 1        सजीव\n",
      "39           ,                 2           ,\n",
      "40         सफल                 1         सफल\n",
      "41       प्यार                 1       प्यार\n",
      "42         भरी                 1         भरी\n",
      "43     बजन्दगी                 1     बजन्दगी\n",
      "44        जीने                 1        जीने\n",
      "45   \\nप्रेररत                 1   \\nप्रेररत\n",
      "46        होते                 1        होते\n",
      "47          आओ                 1          आओ\n",
      "48          इस                 1          इस\n",
      "49      सोंगठन                 1      सोंगठन\n",
      "50    उद्देश्य                 1    उद्देश्य\n",
      "51    प्राद्धि                 1    प्राद्धि\n",
      "52       समथथन                 1       समथथन\n",
      "53        करें                 1        करें\n",
      "54       सिक्त                 1       सिक्त\n",
      "55      योगदान                 1      योगदान\n",
      "56         दें                 1         दें\n",
      "57     धन्यवाद                 1     धन्यवाद\n"
     ]
    }
   ],
   "source": [
    "# Display the updated DataFrame\n",
    "print(df_indian)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b22c29b",
   "metadata": {},
   "source": [
    "### 2. To tokenize the document (article, news, story, assay) of Forighn Language and find the frequency count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd917852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5a39acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the PDF file\n",
    "pdf_file = open(\"persiantext.pdf\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "112a4b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PDF reader\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5a10e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from each page\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83779560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the PDF file\n",
    "pdf_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ee96996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['بهسازی']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['و']\n",
      "['چالش']\n",
      "['ها']\n",
      "['ی']\n",
      "['آن']\n",
      "['\\n']\n",
      "['\\nدر']\n",
      "['دن']\n",
      "['یا']\n",
      "['ی']\n",
      "['مدرن']\n",
      "['امروز']\n",
      "['ی']\n",
      "['،']\n",
      "['نیاز']\n",
      "['به']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['رو']\n",
      "['به']\n",
      "['افزا']\n",
      "['یش']\n",
      "['است']\n",
      "['و']\n",
      "['به']\n",
      "['طور']\n",
      "['متواز']\n",
      "['ی']\n",
      "['با']\n",
      "['ا']\n",
      "['ین']\n",
      "['افزا']\n",
      "['یش،']\n",
      "['مواجهه']\n",
      "['با']\n",
      "['چالش']\n",
      "['ها']\n",
      "['ی']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['نی']\n",
      "['در']\n",
      "['حال']\n",
      "['\\nافزا']\n",
      "['یش']\n",
      "['م']\n",
      "['باشد']\n",
      "['.']\n",
      "['کاهش']\n",
      "['منابع']\n",
      "['طبی']\n",
      "['یع']\n",
      "['و']\n",
      "['وابستگ']\n",
      "['بیش']\n",
      "['از']\n",
      "['حد']\n",
      "['به']\n",
      "['سوختها']\n",
      "['ی']\n",
      "['فسی']\n",
      "['یل،']\n",
      "['از']\n",
      "['جمله']\n",
      "['چالش']\n",
      "['ها']\n",
      "['ی']\n",
      "['مهم']\n",
      "['در']\n",
      "['زمی']\n",
      "['نه']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['\\nاست']\n",
      "['.']\n",
      "['راهحل']\n",
      "['ها']\n",
      "['ی']\n",
      "['برا']\n",
      "['ی']\n",
      "['مقابله']\n",
      "['با']\n",
      "['ا']\n",
      "['ی']\n",
      "['ن']\n",
      "['چالشها']\n",
      "['وجود']\n",
      "['دارد']\n",
      "['.']\n",
      "['یگ']\n",
      "['از']\n",
      "['راه']\n",
      "['ها']\n",
      "['ی']\n",
      "['مهم،']\n",
      "['استفاده']\n",
      "['بهینه']\n",
      "['و']\n",
      "['افزا']\n",
      "['یش']\n",
      "['استفاده']\n",
      "['از']\n",
      "['منابع']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['\\nتجدیدپذیر']\n",
      "['مانند']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['خورشید']\n",
      "['ی']\n",
      "['،']\n",
      "['باد']\n",
      "['و']\n",
      "['آب']\n",
      "['است']\n",
      "['.']\n",
      "['همچنی']\n",
      "['،']\n",
      "['افزا']\n",
      "['ی']\n",
      "['ش']\n",
      "['کارا']\n",
      "['ی']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['در']\n",
      "['مصارف']\n",
      "['مختلف']\n",
      "['و']\n",
      "['ترو']\n",
      "['ی']\n",
      "['ج']\n",
      "['رفتارها']\n",
      "['ی']\n",
      "['مدرن']\n",
      "['و']\n",
      "['\\nپا']\n",
      "['یدار']\n",
      "['نی']\n",
      "['م']\n",
      "['تواند']\n",
      "['کمک']\n",
      "['کند']\n",
      "['.']\n",
      "['عالوه']\n",
      "['بر']\n",
      "['ا']\n",
      "['ی']\n",
      "['ن،']\n",
      "['ن']\n",
      "['یاز']\n",
      "['به']\n",
      "['آموزش']\n",
      "['و']\n",
      "['اطالعرسای']\n",
      "['در']\n",
      "['زمی']\n",
      "['نه']\n",
      "['مدی']\n",
      "['ر']\n",
      "['یت']\n",
      "['صح']\n",
      "['یح']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['از']\n",
      "['اهمیت']\n",
      "['بال']\n",
      "['ی']\n",
      "['برخوردار']\n",
      "['است']\n",
      "['.']\n",
      "['با']\n",
      "['ید']\n",
      "['به']\n",
      "['ترو']\n",
      "['ی']\n",
      "['ج']\n",
      "['مفهوم']\n",
      "['\\nمسئول']\n",
      "['یت']\n",
      "['اجتمایع']\n",
      "['در']\n",
      "['استفاده']\n",
      "['از']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['بیرداز']\n",
      "['یم']\n",
      "['تا']\n",
      "['همگان']\n",
      "['به']\n",
      "['و']\n",
      "['یژه']\n",
      "['جوانان،']\n",
      "['به']\n",
      "['طور']\n",
      "['مسئولنه']\n",
      "['تر']\n",
      "['ی']\n",
      "['با']\n",
      "['مرصف']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['روبرو']\n",
      "['شوند']\n",
      "['.']\n",
      "['به']\n",
      "['ا']\n",
      "['ی']\n",
      "['ن']\n",
      "['ترتیب،']\n",
      "['م']\n",
      "['توانیم']\n",
      "['با']\n",
      "['همکار']\n",
      "['ی']\n",
      "['و']\n",
      "['توجه']\n",
      "['به']\n",
      "['ا']\n",
      "['ین']\n",
      "['موضوعات،']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['پاک']\n",
      "['و']\n",
      "['پا']\n",
      "['یدار']\n",
      "['را']\n",
      "['تضمی']\n",
      "['کرده']\n",
      "['و']\n",
      "['به']\n",
      "['بهساز']\n",
      "['ی']\n",
      "['انرژ']\n",
      "['ی']\n",
      "['در']\n",
      "['جامعه']\n",
      "['و']\n",
      "['\\nجهان']\n",
      "['کمک']\n",
      "['کنیم']\n",
      "['.']\n",
      "<FreqDist with 123 samples and 249 outcomes>\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the Persian text into words\n",
    "import nltk\n",
    "from indicnlp.tokenize import sentence_tokenize, indic_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "#Tokenize sentences\n",
    "sentences = sentence_tokenize.sentence_split(text, lang='persian')\n",
    "\n",
    "# Tokenize words within each sentence\n",
    "tokenized_sentences = [word for sentence in sentences for word in indic_tokenize.trivial_tokenize(sentence)]\n",
    "\n",
    "# Creating a frequency distribution of tokens:\n",
    "frequency_dist = FreqDist(tokenized_sentences)\n",
    "\n",
    "#Print tokenized sentences\n",
    "for persian_tokens in tokenized_sentences:\n",
    "    print(indic_tokenize.trivial_tokenize(persian_tokens))\n",
    "\n",
    "# Print the frequency distribution\n",
    "print(frequency_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11744ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
